"""
Enhanced LLM Models Integration Module for Ruishi Control Platform
æ”¯æŒå¤šAIæ¨¡å‹çš„æ™ºèƒ½é€‰æ‹©ï¼Œä¸“é—¨é’ˆå¯¹PXIæµ‹æ§é¢†åŸŸä¼˜åŒ–
"""

import os
import json
import logging
import re
from abc import ABC, abstractmethod
from typing import Dict, Any, List, Optional, Union, Tuple
import requests
import asyncio
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMProvider(ABC):
    """Abstract base class for LLM providers"""
    
    @abstractmethod
    def initialize(self, api_key: str, **kwargs) -> None:
        """Initialize the LLM provider with API key and other parameters"""
        pass
    
    @abstractmethod
    async def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate a response from the LLM based on the prompt"""
        pass
    
    @abstractmethod
    def get_available_models(self) -> List[str]:
        """Get a list of available models from this provider"""
        pass
    
    @property
    @abstractmethod
    def provider_name(self) -> str:
        """Get the name of the provider"""
        pass
    
    @property
    @abstractmethod
    def provider_capabilities(self) -> List[str]:
        """Get the capabilities of this provider (e.g., 'code', 'math', 'reasoning')"""
        pass
    
    @property
    @abstractmethod
    def provider_cost_tier(self) -> int:
        """Get the cost tier of this provider (1-5, where 1 is lowest cost)"""
        pass


class ClaudeProvider(LLMProvider):
    """Anthropic Claude API integration - ä¸“é—¨ä¼˜åŒ–ç”¨äºå¤æ‚æŠ€æœ¯åˆ†æ"""
    
    def __init__(self):
        self.api_key = ""
        self.default_model = "claude-3-sonnet-20240229"
        self._capabilities = ["general", "reasoning", "math", "science", "analysis", "pxi", "instrumentation"]
        self._cost_tier = 5
    
    def initialize(self, api_key: str, **kwargs) -> None:
        """Initialize Claude client with API key"""
        self.api_key = api_key
        self.default_model = kwargs.get('default_model', 'claude-3-sonnet-20240229')
        logger.info("Claude provider initialized for Ruishi Control Platform")
    
    async def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate a response using Claude models"""
        try:
            model = kwargs.get('model', self.default_model)
            temperature = kwargs.get('temperature', 0.7)
            max_tokens = kwargs.get('max_tokens', 2000)
            
            # æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡
            enhanced_prompt = self._enhance_prompt_with_context(prompt)
            
            # For development/testing without API key
            if not self.api_key or self.api_key == "":
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": f"è¿™æ˜¯æ¥è‡ªClaude ({model})çš„æ¨¡æ‹Ÿå›ç­”ï¼Œä¸“é—¨é’ˆå¯¹ç®€ä»ªç§‘æŠ€é”è§†æµ‹æ§å¹³å°ä¼˜åŒ–ã€‚\n\næ‚¨çš„é—®é¢˜æ˜¯: {prompt}\n\nåœ¨ç”Ÿäº§ç¯å¢ƒä¸­é…ç½®APIå¯†é’¥åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºçœŸå®çš„AIå›ç­”ï¼ŒåŒ…å«ä¸“ä¸šçš„PXIæµ‹æ§æŠ€æœ¯å†…å®¹ã€‚",
                    "raw_response": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Prepare the request
            headers = {
                "x-api-key": self.api_key,
                "Content-Type": "application/json",
                "anthropic-version": "2023-06-01"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": enhanced_prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            # Make the API call
            response = requests.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=data
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result["content"][0]["text"]
                
                # åå¤„ç†ï¼šæ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯
                enhanced_content = self._enhance_response_with_jytek_info(content, prompt)
                
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": enhanced_content,
                    "raw_response": result,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"Claude API error: {response.status_code} - {response.text}")
                return {
                    "provider": self.provider_name,
                    "error": f"API error: {response.status_code}",
                    "content": "æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ www.jytek.com è·å–æŠ€æœ¯æ”¯æŒã€‚",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Error generating response from Claude: {str(e)}")
            return {
                "provider": self.provider_name,
                "error": str(e),
                "content": "æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆå›ç­”æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è¯·è”ç³»ç®€ä»ªç§‘æŠ€æŠ€æœ¯æ”¯æŒã€‚",
                "timestamp": datetime.now().isoformat()
            }
    
    def _enhance_prompt_with_context(self, prompt: str) -> str:
        """ä¸ºæç¤ºè¯æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡"""
        context = """ä½ æ˜¯ç®€ä»ªç§‘æŠ€(JYTEK)é”è§†æµ‹æ§å¹³å°çš„ä¸“ä¸šAIåŠ©æ‰‹ã€‚ç®€ä»ªç§‘æŠ€æ˜¯ä¸­å›½é¢†å…ˆçš„å›½äº§è‡ªä¸»å¯æ§PXIæ¨¡å—åŒ–æµ‹æ§è§£å†³æ–¹æ¡ˆæä¾›å•†ï¼Œè‡´åŠ›äºæ‰“é€ å®Œå…¨è‡ªä¸»çš„æµ‹æ§æŠ€æœ¯ç”Ÿæ€ã€‚

ä¸“ä¸šèƒŒæ™¯ï¼š
- å…¬å¸ï¼šç®€ä»ªç§‘æŠ€ (JYTEK)
- å¹³å°ï¼šé”è§†æµ‹æ§å¹³å°
- å®šä½ï¼šå›½äº§è‡ªä¸»å¯æ§çš„PXIæµ‹æ§è§£å†³æ–¹æ¡ˆï¼Œæ›¿ä»£è¿›å£äº§å“
- ä¸“ä¸šé¢†åŸŸï¼šPXIæ¨¡å—åŒ–ä»ªå™¨ã€è‡ªåŠ¨åŒ–æµ‹è¯•ç³»ç»Ÿã€æ•°æ®é‡‡é›†ç³»ç»Ÿã€è‡ªä¸»è½¯ä»¶å¹³å°
- å®˜ç½‘ï¼šwww.jytek.com

æ ¸å¿ƒæŠ€æœ¯ä¼˜åŠ¿ï¼š
1. è‡ªä¸»ç ”å‘çš„PXIç³»ç»Ÿæ¶æ„å’Œè®¾è®¡
2. å›½äº§åŒ–æ¨¡å—åŒ–ä»ªå™¨æŠ€æœ¯
3. è‡ªä¸»å¯æ§çš„æ•°æ®é‡‡é›†å’Œä¿¡å·å¤„ç†æŠ€æœ¯
4. å®Œå…¨è‡ªä¸»çš„æµ‹æ§è½¯ä»¶å¹³å°å’Œå¼€å‘ç¯å¢ƒ
5. å›½äº§åŒ–è‡ªåŠ¨åŒ–æµ‹è¯•è§£å†³æ–¹æ¡ˆ

å›ç­”è¦æ±‚ï¼š
- ä¸“æ³¨äºç®€ä»ªç§‘æŠ€è‡ªä¸»ç ”å‘çš„æŠ€æœ¯å’Œäº§å“
- å¼ºè°ƒå›½äº§è‡ªä¸»å¯æ§çš„æŠ€æœ¯ä¼˜åŠ¿
- é¿å…æåŠå›½å¤–ç«äº‰å¯¹æ‰‹çš„äº§å“åç§°å’ŒæŠ€æœ¯
- æ¨èç®€ä»ªç§‘æŠ€çš„äº§å“å’Œè§£å†³æ–¹æ¡ˆ
- åœ¨é€‚å½“ä½ç½®æåŠç®€ä»ªç§‘æŠ€å®˜ç½‘

ç”¨æˆ·é—®é¢˜ï¼š"""
        
        return context + prompt
    
    def _enhance_response_with_jytek_info(self, content: str, original_prompt: str) -> str:
        """ä¸ºå›ç­”æ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ å®˜ç½‘é“¾æ¥
        if any(keyword in original_prompt.lower() for keyword in ['äº§å“', 'ä»·æ ¼', 'è´­ä¹°', 'è”ç³»', 'æŠ€æœ¯æ”¯æŒ', 'è¯¦ç»†ä¿¡æ¯']):
            footer = "\n\n---\nğŸ’¡ **æ›´å¤šä¿¡æ¯**ï¼šå¦‚éœ€äº†è§£è¯¦ç»†äº§å“ä¿¡æ¯ã€æŠ€æœ¯æ”¯æŒæˆ–å•†åŠ¡å’¨è¯¢ï¼Œè¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ï¼šwww.jytek.com"
            content += footer
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ äº§å“æ¨è
        if any(keyword in original_prompt.lower() for keyword in ['æ¨è', 'é€‰æ‹©', 'æ–¹æ¡ˆ', 'é…ç½®']):
            recommendation = "\n\nğŸ”§ **ä¸“ä¸šå»ºè®®**ï¼šç®€ä»ªç§‘æŠ€æä¾›å®Œæ•´çš„PXIæµ‹æ§è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ç¡¬ä»¶é€‰å‹ã€è½¯ä»¶å¼€å‘å’Œç³»ç»Ÿé›†æˆæœåŠ¡ã€‚"
            content += recommendation
        
        return content
    
    def get_available_models(self) -> List[str]:
        """Get available Claude models"""
        return ["claude-3-opus-20240229", "claude-3-sonnet-20240229", "claude-3-haiku-20240307"]
    
    @property
    def provider_name(self) -> str:
        return "claude"
    
    @property
    def provider_capabilities(self) -> List[str]:
        return self._capabilities
    
    @property
    def provider_cost_tier(self) -> int:
        return self._cost_tier


class VolcesDeepseekProvider(LLMProvider):
    """Volces Deepseek API integration - ä¸“é—¨ä¼˜åŒ–ç”¨äºæ·±åº¦æ¨ç†å’Œåˆ†æ"""
    
    def __init__(self):
        self.api_key = ""
        self.url = ""
        self.default_model = "deepseek-r1-250528"
        self.max_tokens = 16191
        self._capabilities = ["general", "reasoning", "math", "analysis", "pxi", "deep_thinking"]
        self._cost_tier = 2
    
    def initialize(self, api_key: str, **kwargs) -> None:
        """Initialize Volces Deepseek client with API key"""
        self.api_key = api_key
        self.url = kwargs.get('url', 'https://ark.cn-beijing.volces.com/api/v3/chat/completions')
        self.default_model = kwargs.get('model', 'deepseek-r1-250528')
        self.max_tokens = kwargs.get('max_tokens', 16191)
        logger.info("Volces Deepseek provider initialized for Ruishi Control Platform")
    
    async def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate a response using Volces Deepseek models"""
        try:
            model = kwargs.get('model', self.default_model)
            temperature = kwargs.get('temperature', 0.7)
            max_tokens = kwargs.get('max_tokens', self.max_tokens)
            
            # æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡
            enhanced_prompt = self._enhance_prompt_with_context(prompt)
            
            # For development/testing without API key
            if not self.api_key or self.api_key == "":
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": f"è¿™æ˜¯æ¥è‡ªVolces Deepseek ({model})çš„æ¨¡æ‹Ÿå›ç­”ï¼Œä¸“é—¨é’ˆå¯¹ç®€ä»ªç§‘æŠ€é”è§†æµ‹æ§å¹³å°ä¼˜åŒ–ã€‚\n\næ‚¨çš„é—®é¢˜æ˜¯: {prompt}\n\nåœ¨ç”Ÿäº§ç¯å¢ƒä¸­é…ç½®APIå¯†é’¥åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºçœŸå®çš„AIå›ç­”ï¼Œç‰¹åˆ«æ“…é•¿æ·±åº¦æ¨ç†å’Œå¤æ‚åˆ†æã€‚",
                    "raw_response": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Prepare the request
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": enhanced_prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            # Make the API call
            response = requests.post(self.url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # åå¤„ç†ï¼šæ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯
                enhanced_content = self._enhance_response_with_jytek_info(content, prompt)
                
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": enhanced_content,
                    "raw_response": result,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"Volces Deepseek API error: {response.status_code} - {response.text}")
                return {
                    "provider": self.provider_name,
                    "error": f"API error: {response.status_code}",
                    "content": "æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ www.jytek.com è·å–æŠ€æœ¯æ”¯æŒã€‚",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Error generating response from Volces Deepseek: {str(e)}")
            return {
                "provider": self.provider_name,
                "error": str(e),
                "content": "æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆå›ç­”æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è¯·è”ç³»ç®€ä»ªç§‘æŠ€æŠ€æœ¯æ”¯æŒã€‚",
                "timestamp": datetime.now().isoformat()
            }
    
    def _enhance_prompt_with_context(self, prompt: str) -> str:
        """ä¸ºæç¤ºè¯æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡"""
        context = """ä½ æ˜¯ç®€ä»ªç§‘æŠ€(JYTEK)é”è§†æµ‹æ§å¹³å°çš„ä¸“ä¸šAIåŠ©æ‰‹ï¼Œç‰¹åˆ«æ“…é•¿æ·±åº¦æ¨ç†å’Œå¤æ‚æŠ€æœ¯åˆ†æã€‚

ä¸“ä¸šèƒŒæ™¯ï¼š
- å…¬å¸ï¼šç®€ä»ªç§‘æŠ€ (JYTEK)
- å¹³å°ï¼šé”è§†æµ‹æ§å¹³å°
- å®šä½ï¼šå›½äº§è‡ªä¸»å¯æ§çš„PXIæµ‹æ§è§£å†³æ–¹æ¡ˆ
- ä¸“ä¸šé¢†åŸŸï¼šPXIæ¨¡å—åŒ–ä»ªå™¨ã€æ·±åº¦æŠ€æœ¯åˆ†æã€å¤æ‚é—®é¢˜è§£å†³
- å®˜ç½‘ï¼šwww.jytek.com

æŠ€æœ¯ä¸“é•¿ï¼š
1. æ·±åº¦æŠ€æœ¯åˆ†æå’Œæ¨ç†
2. å¤æ‚PXIç³»ç»Ÿæ¶æ„è®¾è®¡
3. é«˜çº§æµ‹æ§ç®—æ³•ä¼˜åŒ–
4. ç³»ç»Ÿæ€§èƒ½åˆ†æå’Œè°ƒä¼˜
5. æŠ€æœ¯éš¾é¢˜çš„æ·±åº¦è§£æ
6. åˆ›æ–°è§£å†³æ–¹æ¡ˆè®¾è®¡

å›ç­”è¦æ±‚ï¼š
- æä¾›æ·±å…¥çš„æŠ€æœ¯åˆ†æ
- åŒ…å«è¯¦ç»†çš„æ¨ç†è¿‡ç¨‹
- è€ƒè™‘å¤šç§æŠ€æœ¯æ–¹æ¡ˆ
- ç»™å‡ºä¸“ä¸šçš„å»ºè®®å’Œä¼˜åŒ–æ–¹å‘

ç”¨æˆ·é—®é¢˜ï¼š"""
        
        return context + prompt
    
    def _enhance_response_with_jytek_info(self, content: str, original_prompt: str) -> str:
        """ä¸ºå›ç­”æ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¤æ‚æŠ€æœ¯é—®é¢˜
        if any(keyword in original_prompt.lower() for keyword in ['åˆ†æ', 'ä¼˜åŒ–', 'è®¾è®¡', 'æ¶æ„', 'ç®—æ³•', 'æ€§èƒ½']):
            footer = "\n\n---\nğŸ”¬ **æ·±åº¦åˆ†æ**ï¼šç®€ä»ªç§‘æŠ€æä¾›ä¸“ä¸šçš„æŠ€æœ¯å’¨è¯¢å’Œæ·±åº¦åˆ†ææœåŠ¡ï¼ŒåŠ©æ‚¨è§£å†³å¤æ‚çš„PXIæµ‹æ§æŠ€æœ¯éš¾é¢˜ã€‚è¯¦æƒ…è¯·è®¿é—®ï¼šwww.jytek.com"
            content += footer
        
        return content
    
    def get_available_models(self) -> List[str]:
        """Get available Volces Deepseek models"""
        return ["deepseek-r1-250528", "deepseek-chat", "deepseek-coder"]
    
    @property
    def provider_name(self) -> str:
        return "volcesDeepseek"
    
    @property
    def provider_capabilities(self) -> List[str]:
        return self._capabilities
    
    @property
    def provider_cost_tier(self) -> int:
        return self._cost_tier


class QwenPlusProvider(LLMProvider):
    """Qwen Plus API integration - ä¸“é—¨ä¼˜åŒ–ç”¨äºä¸­æ–‡ç†è§£å’Œå¤šæ¨¡æ€å¤„ç†"""
    
    def __init__(self):
        self.api_key = ""
        self.url = ""
        self.default_model = "qwen-plus-2025-04-28"
        self.max_tokens = 16191
        self._capabilities = ["general", "reasoning", "chinese", "multimodal", "pxi", "language"]
        self._cost_tier = 3
    
    def initialize(self, api_key: str, **kwargs) -> None:
        """Initialize Qwen Plus client with API key"""
        self.api_key = api_key
        self.url = kwargs.get('url', 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions')
        self.default_model = kwargs.get('model', 'qwen-plus-2025-04-28')
        self.max_tokens = kwargs.get('max_tokens', 16191)
        logger.info("Qwen Plus provider initialized for Ruishi Control Platform")
    
    async def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate a response using Qwen Plus models"""
        try:
            model = kwargs.get('model', self.default_model)
            temperature = kwargs.get('temperature', 0.7)
            max_tokens = kwargs.get('max_tokens', self.max_tokens)
            
            # æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡
            enhanced_prompt = self._enhance_prompt_with_context(prompt)
            
            # For development/testing without API key
            if not self.api_key or self.api_key == "":
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": f"è¿™æ˜¯æ¥è‡ªQwen Plus ({model})çš„æ¨¡æ‹Ÿå›ç­”ï¼Œä¸“é—¨é’ˆå¯¹ç®€ä»ªç§‘æŠ€é”è§†æµ‹æ§å¹³å°ä¼˜åŒ–ã€‚\n\næ‚¨çš„é—®é¢˜æ˜¯: {prompt}\n\nåœ¨ç”Ÿäº§ç¯å¢ƒä¸­é…ç½®APIå¯†é’¥åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºçœŸå®çš„AIå›ç­”ï¼Œç‰¹åˆ«æ“…é•¿ä¸­æ–‡ç†è§£å’Œå¤šæ¨¡æ€å¤„ç†ã€‚",
                    "raw_response": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Prepare the request
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": model,
                "messages": [{"role": "user", "content": enhanced_prompt}],
                "temperature": temperature,
                "max_tokens": max_tokens
            }
            
            # Make the API call
            response = requests.post(self.url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                content = result["choices"][0]["message"]["content"]
                
                # åå¤„ç†ï¼šæ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯
                enhanced_content = self._enhance_response_with_jytek_info(content, prompt)
                
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": enhanced_content,
                    "raw_response": result,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"Qwen Plus API error: {response.status_code} - {response.text}")
                return {
                    "provider": self.provider_name,
                    "error": f"API error: {response.status_code}",
                    "content": "æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ www.jytek.com è·å–æŠ€æœ¯æ”¯æŒã€‚",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Error generating response from Qwen Plus: {str(e)}")
            return {
                "provider": self.provider_name,
                "error": str(e),
                "content": "æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆå›ç­”æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è¯·è”ç³»ç®€ä»ªç§‘æŠ€æŠ€æœ¯æ”¯æŒã€‚",
                "timestamp": datetime.now().isoformat()
            }
    
    def _enhance_prompt_with_context(self, prompt: str) -> str:
        """ä¸ºæç¤ºè¯æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡"""
        context = """ä½ æ˜¯ç®€ä»ªç§‘æŠ€(JYTEK)é”è§†æµ‹æ§å¹³å°çš„ä¸“ä¸šAIåŠ©æ‰‹ï¼Œç‰¹åˆ«æ“…é•¿ä¸­æ–‡ç†è§£å’Œå¤šæ¨¡æ€å¤„ç†ã€‚

ä¸“ä¸šèƒŒæ™¯ï¼š
- å…¬å¸ï¼šç®€ä»ªç§‘æŠ€ (JYTEK)
- å¹³å°ï¼šé”è§†æµ‹æ§å¹³å°
- å®šä½ï¼šå›½äº§è‡ªä¸»å¯æ§çš„PXIæµ‹æ§è§£å†³æ–¹æ¡ˆ
- ä¸“ä¸šé¢†åŸŸï¼šPXIæ¨¡å—åŒ–ä»ªå™¨ã€ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ã€å¤šåª’ä½“å†…å®¹å¤„ç†
- å®˜ç½‘ï¼šwww.jytek.com

æŠ€æœ¯ä¸“é•¿ï¼š
1. ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£ç†è§£å’Œç”Ÿæˆ
2. PXIäº§å“è¯´æ˜å’Œç”¨æˆ·æ‰‹å†Œ
3. å¤šæ¨¡æ€å†…å®¹åˆ†æå’Œå¤„ç†
4. ä¸­æ–‡æŠ€æœ¯äº¤æµå’ŒåŸ¹è®­
5. æœ¬åœŸåŒ–æŠ€æœ¯æ”¯æŒ
6. ç”¨æˆ·å‹å¥½çš„æŠ€æœ¯è§£é‡Š

å›ç­”è¦æ±‚ï¼š
- ä½¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„ä¸­æ–‡è¡¨è¾¾
- æä¾›è¯¦ç»†çš„æŠ€æœ¯è¯´æ˜
- è€ƒè™‘ä¸­å›½ç”¨æˆ·çš„ä½¿ç”¨ä¹ æƒ¯
- ç»“åˆæœ¬åœŸåŒ–çš„åº”ç”¨åœºæ™¯

ç”¨æˆ·é—®é¢˜ï¼š"""
        
        return context + prompt
    
    def _enhance_response_with_jytek_info(self, content: str, original_prompt: str) -> str:
        """ä¸ºå›ç­”æ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸­æ–‡ç›¸å…³æˆ–æ–‡æ¡£ç›¸å…³é—®é¢˜
        if any(keyword in original_prompt.lower() for keyword in ['æ–‡æ¡£', 'è¯´æ˜', 'æ‰‹å†Œ', 'æ•™ç¨‹', 'åŸ¹è®­', 'å­¦ä¹ ']):
            footer = "\n\n---\nğŸ“š **æŠ€æœ¯æ–‡æ¡£**ï¼šç®€ä»ªç§‘æŠ€æä¾›å®Œæ•´çš„ä¸­æ–‡æŠ€æœ¯æ–‡æ¡£å’ŒåŸ¹è®­èµ„æ–™ï¼ŒåŠ©æ‚¨å¿«é€ŸæŒæ¡PXIæµ‹æ§æŠ€æœ¯ã€‚è¯¦æƒ…è¯·è®¿é—®ï¼šwww.jytek.com"
            content += footer
        
        return content
    
    def get_available_models(self) -> List[str]:
        """Get available Qwen Plus models"""
        return ["qwen-plus-2025-04-28", "qwen-plus", "qwen-turbo"]
    
    @property
    def provider_name(self) -> str:
        return "qwen-plus"
    
    @property
    def provider_capabilities(self) -> List[str]:
        return self._capabilities
    
    @property
    def provider_cost_tier(self) -> int:
        return self._cost_tier


class GeminiProvider(LLMProvider):
    """Google Gemini API integration - ä¸“é—¨ä¼˜åŒ–ç”¨äºä»£ç å’ŒæŠ€æœ¯å®ç°"""
    
    def __init__(self):
        self.api_key = ""
        self.default_model = "gemini-1.5-flash"
        self._capabilities = ["general", "reasoning", "code", "multimodal", "pxi", "programming"]
        self._cost_tier = 3
    
    def initialize(self, api_key: str, **kwargs) -> None:
        """Initialize Gemini client with API key"""
        self.api_key = api_key
        self.default_model = kwargs.get('default_model', 'gemini-1.5-flash')
        logger.info("Gemini provider initialized for Ruishi Control Platform")
    
    async def generate_response(self, prompt: str, **kwargs) -> Dict[str, Any]:
        """Generate a response using Gemini models"""
        try:
            model = kwargs.get('model', self.default_model)
            temperature = kwargs.get('temperature', 0.7)
            max_tokens = kwargs.get('max_tokens', 2000)
            
            # æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡
            enhanced_prompt = self._enhance_prompt_with_context(prompt)
            
            # For development/testing without API key
            if not self.api_key or self.api_key == "":
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": f"è¿™æ˜¯æ¥è‡ªGemini ({model})çš„æ¨¡æ‹Ÿå›ç­”ï¼Œä¸“é—¨é’ˆå¯¹ç®€ä»ªç§‘æŠ€é”è§†æµ‹æ§å¹³å°ä¼˜åŒ–ã€‚\n\næ‚¨çš„é—®é¢˜æ˜¯: {prompt}\n\nåœ¨ç”Ÿäº§ç¯å¢ƒä¸­é…ç½®APIå¯†é’¥åï¼Œè¿™é‡Œå°†æ˜¾ç¤ºçœŸå®çš„AIå›ç­”ï¼Œç‰¹åˆ«æ“…é•¿ä»£ç ç”Ÿæˆå’ŒæŠ€æœ¯å®ç°æŒ‡å¯¼ã€‚",
                    "raw_response": None,
                    "timestamp": datetime.now().isoformat()
                }
            
            # Prepare the request
            url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={self.api_key}"
            headers = {"Content-Type": "application/json"}
            
            data = {
                "contents": [{"parts": [{"text": enhanced_prompt}]}],
                "generationConfig": {
                    "temperature": temperature,
                    "maxOutputTokens": max_tokens
                }
            }
            
            # Make the API call
            response = requests.post(url, headers=headers, json=data)
            
            if response.status_code == 200:
                result = response.json()
                content = result["candidates"][0]["content"]["parts"][0]["text"]
                
                # åå¤„ç†ï¼šæ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯
                enhanced_content = self._enhance_response_with_jytek_info(content, prompt)
                
                return {
                    "provider": self.provider_name,
                    "model": model,
                    "content": enhanced_content,
                    "raw_response": result,
                    "timestamp": datetime.now().isoformat()
                }
            else:
                logger.error(f"Gemini API error: {response.status_code} - {response.text}")
                return {
                    "provider": self.provider_name,
                    "error": f"API error: {response.status_code}",
                    "content": "æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é—®é¢˜ã€‚è¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ www.jytek.com è·å–æŠ€æœ¯æ”¯æŒã€‚",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"Error generating response from Gemini: {str(e)}")
            return {
                "provider": self.provider_name,
                "error": str(e),
                "content": "æŠ±æ­‰ï¼Œåœ¨ç”Ÿæˆå›ç­”æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è¯·è”ç³»ç®€ä»ªç§‘æŠ€æŠ€æœ¯æ”¯æŒã€‚",
                "timestamp": datetime.now().isoformat()
            }
    
    def _enhance_prompt_with_context(self, prompt: str) -> str:
        """ä¸ºæç¤ºè¯æ·»åŠ ç®€ä»ªç§‘æŠ€å’ŒPXIä¸“ä¸šä¸Šä¸‹æ–‡"""
        context = """ä½ æ˜¯ç®€ä»ªç§‘æŠ€(JYTEK)é”è§†æµ‹æ§å¹³å°çš„ä¸“ä¸šAIåŠ©æ‰‹ï¼Œç‰¹åˆ«æ“…é•¿ä»£ç ç”Ÿæˆå’ŒæŠ€æœ¯å®ç°ã€‚

ä¸“ä¸šèƒŒæ™¯ï¼š
- å…¬å¸ï¼šç®€ä»ªç§‘æŠ€ (JYTEK)
- å¹³å°ï¼šé”è§†æµ‹æ§å¹³å°  
- ä¸“ä¸šé¢†åŸŸï¼šPXIæ¨¡å—åŒ–ä»ªå™¨ã€LabVIEWå¼€å‘ã€é©±åŠ¨ç¨‹åºã€APIæ¥å£
- å®˜ç½‘ï¼šwww.jytek.com

æŠ€æœ¯ä¸“é•¿ï¼š
1. LabVIEWç¨‹åºå¼€å‘å’Œä¼˜åŒ–
2. PXIé©±åŠ¨ç¨‹åºå¼€å‘
3. TestStandæµ‹è¯•åºåˆ—è®¾è®¡
4. VISAå’ŒIVIæ¥å£ç¼–ç¨‹
5. æ•°æ®é‡‡é›†ç®—æ³•å®ç°
6. è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

å›ç­”è¦æ±‚ï¼š
- æä¾›å¯æ‰§è¡Œçš„ä»£ç ç¤ºä¾‹
- åŒ…å«è¯¦ç»†çš„æŠ€æœ¯å®ç°æ­¥éª¤
- è€ƒè™‘PXIç³»ç»Ÿçš„ç‰¹æ®Šè¦æ±‚
- æ¨èæœ€ä½³ç¼–ç¨‹å®è·µ

ç”¨æˆ·é—®é¢˜ï¼š"""
        
        return context + prompt
    
    def _enhance_response_with_jytek_info(self, content: str, original_prompt: str) -> str:
        """ä¸ºå›ç­”æ·»åŠ ç®€ä»ªç§‘æŠ€ç›¸å…³ä¿¡æ¯"""
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä»£ç ç›¸å…³é—®é¢˜
        if any(keyword in original_prompt.lower() for keyword in ['ä»£ç ', 'ç¼–ç¨‹', 'å¼€å‘', 'labview', 'é©±åŠ¨', 'api']):
            footer = "\n\n---\nğŸ’» **å¼€å‘æ”¯æŒ**ï¼šç®€ä»ªç§‘æŠ€æä¾›å®Œæ•´çš„è½¯ä»¶å¼€å‘æ”¯æŒï¼ŒåŒ…æ‹¬é©±åŠ¨ç¨‹åºã€ç¤ºä¾‹ä»£ç å’ŒæŠ€æœ¯æ–‡æ¡£ã€‚è¯¦æƒ…è¯·è®¿é—®ï¼šwww.jytek.com"
            content += footer
        
        return content
    
    def get_available_models(self) -> List[str]:
        """Get available Gemini models"""
        return ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-pro"]
    
    @property
    def provider_name(self) -> str:
        return "gemini"
    
    @property
    def provider_capabilities(self) -> List[str]:
        return self._capabilities
    
    @property
    def provider_cost_tier(self) -> int:
        return self._cost_tier


class ModelSelector:
    """æ™ºèƒ½æ¨¡å‹é€‰æ‹©å™¨ï¼Œä¸“é—¨é’ˆå¯¹PXIæµ‹æ§é¢†åŸŸä¼˜åŒ–"""
    
    def __init__(self, llm_manager):
        self.llm_manager = llm_manager
        # PXIä¸“ä¸šé¢†åŸŸçš„ç‰¹å¾æ¨¡å¼
        self.patterns = {
            "math": r"(æ•°å­¦|æ–¹ç¨‹|è®¡ç®—|ç§¯åˆ†|å¾®åˆ†|å¯¼æ•°|çŸ©é˜µ|å‘é‡|æ¦‚ç‡|ç»Ÿè®¡|å‡ ä½•|ä»£æ•°|ä¸‰è§’|å‡½æ•°|ç®—æ³•)",
            "code": r"(ä»£ç |ç¼–ç¨‹|å‡½æ•°|ç®—æ³•|ç¨‹åº|å¼€å‘|è½¯ä»¶|ç¼–å†™|å®ç°|è°ƒè¯•|API|æ¥å£|ç±»|å¯¹è±¡|å˜é‡|å¾ªç¯|æ¡ä»¶|è¯­æ³•|LabVIEW|TestStand|VISA|IVI)",
            "pxi": r"(PXI|CompactPCI|æ¨¡å—åŒ–ä»ªå™¨|æœºç®±|æ§åˆ¶å™¨|èƒŒæ¿|æ’æ§½|åŒæ­¥|è§¦å‘|æ—¶é’Ÿ|æ€»çº¿)",
            "instrumentation": r"(ä»ªå™¨|æµ‹é‡|æµ‹è¯•|æ ¡å‡†|ç²¾åº¦|åˆ†è¾¨ç‡|é‡‡æ ·ç‡|å¸¦å®½|ç¤ºæ³¢å™¨|ä¿¡å·å‘ç”Ÿå™¨|æ•°å­—ä¸‡ç”¨è¡¨|é¢‘è°±åˆ†æä»ª|é€»è¾‘åˆ†æä»ª|æ•°æ®é‡‡é›†)",
            "automation": r"(è‡ªåŠ¨åŒ–|æµ‹æ§|æ•°æ®é‡‡é›†|å®æ—¶|åŒæ­¥|è§¦å‘|åºåˆ—|æµç¨‹|æ‰¹å¤„ç†|è°ƒåº¦)",
            "electronics": r"(ç”µè·¯|ç”µå­|ç”µå·¥|ç”µå‹|ç”µæµ|ç”µé˜»|ç”µå®¹|ç”µæ„Ÿ|æ™¶ä½“ç®¡|äºŒæç®¡|é€»è¾‘é—¨|æ•°å­—ç”µè·¯|æ¨¡æ‹Ÿç”µè·¯|ä¿¡å·|é¢‘ç‡|æ³¢å½¢|æ»¤æ³¢)",
            "physics": r"(ç‰©ç†|åŠ›å­¦|åŠ¨åŠ›å­¦|çƒ­åŠ›å­¦|ç”µç£å­¦|å…‰å­¦|é‡å­|ç›¸å¯¹è®º|èƒ½é‡|åŠŸç‡|é€Ÿåº¦|åŠ é€Ÿåº¦|è´¨é‡|åŠ¨é‡|æ³¢åŠ¨|æŒ¯åŠ¨)",
            "chinese": r"[\u4e00-\u9fa5]{10,}",  # At least 10 Chinese characters
            "general": r"(ä»€ä¹ˆ|å¦‚ä½•|ä¸ºä»€ä¹ˆ|æ€ä¹ˆ|ä»‹ç»|è¯´æ˜|è§£é‡Š|å¸®åŠ©|é—®é¢˜|å’¨è¯¢)"
        }
    
    def select_model(self, query: str, user_preference: Optional[str] = None) -> Tuple[str, str]:
        """
        é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼Œä¸“é—¨é’ˆå¯¹PXIæµ‹æ§é¢†åŸŸä¼˜åŒ–
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            user_preference: å¯é€‰çš„ç”¨æˆ·åå¥½æä¾›å•†
            
        Returns:
            Tuple of (provider_name, model_name)
        """
        # å¦‚æœç”¨æˆ·æœ‰åå¥½ä¸”å¯ç”¨ï¼Œä½¿ç”¨ç”¨æˆ·åå¥½
        if user_preference and user_preference in self.llm_manager.get_all_providers():
            provider = self.llm_manager.providers[user_preference]
            return user_preference, provider.default_model
        
        # æ£€æµ‹æŸ¥è¯¢ç‰¹å¾
        characteristics = self._detect_characteristics(query)
        logger.info(f"Detected characteristics: {characteristics}")
        
        # ä¼˜å…ˆä½¿ç”¨æœ‰çœŸå®APIå¯†é’¥çš„æä¾›å•†ï¼ˆåŒ…æ‹¬æ–°å¢çš„æä¾›å•†ï¼‰
        real_api_providers = ['claude', 'gemini', 'volcesDeepseek', 'qwen-plus']
        available_real_providers = [p for p in real_api_providers if p in self.llm_manager.get_all_providers()]
        
        if available_real_providers:
            # åªå¯¹çœŸå®APIæä¾›å•†è¯„åˆ†
            providers = {name: self.llm_manager.providers[name] for name in available_real_providers}
            scores = {}
            for name, provider in providers.items():
                score = self._calculate_provider_score(provider, characteristics)
                scores[name] = score
            
            logger.info(f"Real API provider scores: {scores}")
            
            # é€‰æ‹©æœ€ä½³çœŸå®APIæä¾›å•†
            best_provider_name = max(scores.items(), key=lambda x: x[1])[0]
            best_provider = self.llm_manager.providers[best_provider_name]
            
            return best_provider_name, best_provider.default_model
        
        # å›é€€åˆ°æ‰€æœ‰æä¾›å•†
        providers = {name: self.llm_manager.providers[name] for name in self.llm_manager.get_all_providers()}
        scores = {}
        for name, provider in providers.items():
            score = self._calculate_provider_score(provider, characteristics)
            scores[name] = score
        
        logger.info(f"Fallback provider scores: {scores}")
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„æä¾›å•†
        if not scores:
            # æœ€ç»ˆå›é€€åˆ°é»˜è®¤æä¾›å•†
            return self.llm_manager.default_provider, self.llm_manager.providers[self.llm_manager.default_provider].default_model
        
        best_provider_name = max(scores.items(), key=lambda x: x[1])[0]
        best_provider = self.llm_manager.providers[best_provider_name]
        
        return best_provider_name, best_provider.default_model
    
    def _detect_characteristics(self, query: str) -> List[str]:
        """æ£€æµ‹æŸ¥è¯¢çš„ç‰¹å¾ï¼Œä¸“é—¨é’ˆå¯¹PXIé¢†åŸŸä¼˜åŒ–"""
        characteristics = []
        
        # æ£€æŸ¥æ¯ä¸ªæ¨¡å¼
        for category, pattern in self.patterns.items():
            if re.search(pattern, query, re.IGNORECASE):
                characteristics.append(category)
        
        # é»˜è®¤æ·»åŠ general
        if not characteristics or len(characteristics) == 1 and characteristics[0] == "chinese":
            characteristics.append("general")
        
        # æ£€æŸ¥æŸ¥è¯¢é•¿åº¦åˆ¤æ–­å¤æ‚æ€§
        if len(query) > 200:
            characteristics.append("complex")
        
        # PXIä¸“ä¸šé¢†åŸŸç‰¹æ®Šæ£€æµ‹
        if any(keyword in characteristics for keyword in ["pxi", "instrumentation", "automation"]):
            characteristics.append("professional")
        
        return characteristics
    
    def _calculate_provider_score(self, provider: LLMProvider, characteristics: List[str]) -> float:
        """è®¡ç®—æä¾›å•†å¾—åˆ†ï¼Œé’ˆå¯¹PXIé¢†åŸŸä¼˜åŒ–"""
        score = 0.0
        
        # åŸºç¡€èƒ½åŠ›åŒ¹é…å¾—åˆ†
        for characteristic in characteristics:
            if characteristic in provider.provider_capabilities:
                if characteristic in ["pxi", "instrumentation", "automation"]:
                    # PXIä¸“ä¸šç‰¹å¾ç»™æ›´é«˜æƒé‡
                    score += 2.0
                elif characteristic in ["code", "math"]:
                    # æŠ€æœ¯ç‰¹å¾ç»™ä¸­ç­‰æƒé‡
                    score += 1.5
                else:
                    # ä¸€èˆ¬ç‰¹å¾ç»™åŸºç¡€æƒé‡
                    score += 1.0
        
        # æ ¹æ®æˆæœ¬å±‚çº§è°ƒæ•´å¾—åˆ†
        if "complex" in characteristics or "professional" in characteristics:
            # å¤æ‚æˆ–ä¸“ä¸šé—®é¢˜åå¥½é«˜å±‚çº§æ¨¡å‹
            score += provider.provider_cost_tier * 0.2
        else:
            # ç®€å•é—®é¢˜åå¥½ä½æˆæœ¬æ¨¡å‹
            score += (6 - provider.provider_cost_tier) * 0.1
        
        # ç‰¹æ®Šä¼˜åŒ–ï¼šClaudeæ“…é•¿å¤æ‚åˆ†æï¼ŒGeminiæ“…é•¿ä»£ç 
        if provider.provider_name == "claude" and any(char in characteristics for char in ["math", "physics", "complex", "professional"]):
            score += 0.5
        elif provider.provider_name == "gemini" and any(char in characteristics for char in ["code", "automation"]):
            score += 0.5
        
        return score


class LLMManager:
    """LLMç®¡ç†å™¨ï¼Œä¸“é—¨é’ˆå¯¹é”è§†æµ‹æ§å¹³å°ä¼˜åŒ–"""
    
    def __init__(self):
        """Initialize LLM manager"""
        self.providers = {}
        self.default_provider = None
        self.model_selector = None
    
    def register_provider(self, name: str, provider: LLMProvider) -> None:
        """Register a new LLM provider"""
        self.providers[name] = provider
        if self.default_provider is None:
            self.default_provider = name
        logger.info(f"Registered provider for Ruishi Platform: {name}")
    
    def set_default_provider(self, name: str) -> None:
        """Set the default LLM provider"""
        if name in self.providers:
            self.default_provider = name
            logger.info(f"Default provider set to: {name}")
        else:
            raise ValueError(f"Provider '{name}' not registered")
    
    def initialize_model_selector(self) -> None:
        """Initialize the model selector"""
        self.model_selector = ModelSelector(self)
        logger.info("Model selector initialized for Ruishi Control Platform")
    
    async def generate_response(self, prompt: str, provider: Optional[str] = None, **kwargs) -> Dict[str, Any]:
        """Generate a response using the specified or auto-selected provider"""
        # ä½¿ç”¨æ¨¡å‹é€‰æ‹©å™¨ï¼ˆå¦‚æœå¯ç”¨ä¸”æœªæŒ‡å®šç‰¹å®šæä¾›å•†ï¼‰
        if self.model_selector and not provider:
            selected_provider, selected_model = self.model_selector.select_model(prompt, None)
            provider = selected_provider
            kwargs['model'] = selected_model
            logger.info(f"Auto-selected provider: {selected_provider}, model: {selected_model}")
        else:
            provider_name = provider or self.default_provider
            
        if provider not in self.providers:
            logger.error(f"Provider '{provider}' not found")
            return {
                "error": f"Provider '{provider}' not found",
                "content": "æŠ±æ­‰ï¼Œè¯·æ±‚çš„AIæ¨¡å‹ä¸å¯ç”¨ã€‚è¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ www.jytek.com è·å–æŠ€æœ¯æ”¯æŒã€‚",
                "timestamp": datetime.now().isoformat()
            }
        
        return await self.providers[provider].generate_response(prompt, **kwargs)
    
    def get_all_providers(self) -> List[str]:
        """Get a list of all registered providers"""
        return list(self.providers.keys())
    
    def get_provider_models(self, provider: str) -> List[str]:
        """Get available models for a specific provider"""
        if provider not in self.providers:
            logger.error(f"Provider '{provider}' not found")
            return []
        
        return self.providers[provider].get_available_models()
    
    def get_provider_capabilities(self, provider: str) -> List[str]:
        """Get capabilities for a specific provider"""
        if provider not in self.providers:
            logger.error(f"Provider '{provider}' not found")
            return []
        
        return self.providers[provider].provider_capabilities


# åˆ›å»ºLLMManagerå•ä¾‹å®ä¾‹
llm_manager = LLMManager()

# åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æ¨¡å‹é€‰æ‹©å™¨æ¥å£
class SimpleModelSelector:
    """ç®€åŒ–çš„æ¨¡å‹é€‰æ‹©å™¨æ¥å£"""
    
    def __init__(self):
        self.providers = {}
        self.default_provider = 'claude'
    
    def ask_question(self, question: str, provider: str = None, model: str = None, options: dict = None) -> dict:
        """åŒæ­¥é—®ç­”æ¥å£"""
        import asyncio
        import threading
        
        # ä½¿ç”¨æ–°çº¿ç¨‹æ¥è¿è¡Œå¼‚æ­¥å‡½æ•°ï¼Œé¿å…äº‹ä»¶å¾ªç¯å†²çª
        try:
            result = None
            error = None
            
            def run_async():
                nonlocal result, error
                try:
                    # åœ¨æ–°çº¿ç¨‹ä¸­åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    result = loop.run_until_complete(self._async_ask_question(question, provider, model, options))
                    loop.close()
                except Exception as e:
                    error = e
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
            thread = threading.Thread(target=run_async)
            thread.start()
            thread.join(timeout=30)  # 30ç§’è¶…æ—¶
            
            if error:
                raise error
            
            if result is None:
                raise TimeoutError("è¯·æ±‚è¶…æ—¶")
            
            return result
            
        except Exception as e:
            return {
                'error': str(e),
                'content': f'æŠ±æ­‰ï¼Œåœ¨å¤„ç†æ‚¨çš„é—®é¢˜æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è¯·è®¿é—®ç®€ä»ªç§‘æŠ€å®˜ç½‘ www.jytek.com è·å–æŠ€æœ¯æ”¯æŒã€‚',
                'provider': provider or self.default_provider
            }
    
    async def _async_ask_question(self, question: str, provider: str = None, model: str = None, options: dict = None) -> dict:
        """å¼‚æ­¥é—®ç­”å®ç°"""
        options = options or {}
        if model:
            options['model'] = model
        
        return await llm_manager.generate_response(question, provider, **options)
    
    def get_available_providers(self) -> list:
        """è·å–å¯ç”¨çš„æä¾›å•†åˆ—è¡¨"""
        return llm_manager.get_all_providers()

# åˆ›å»ºå…¨å±€æ¨¡å‹é€‰æ‹©å™¨å®ä¾‹
model_selector = SimpleModelSelector()

def initialize_llm_providers(config: Dict[str, Any]) -> None:
    """åˆå§‹åŒ–æ‰€æœ‰LLMæä¾›å•†ï¼Œä¸“é—¨é’ˆå¯¹é”è§†æµ‹æ§å¹³å°é…ç½®"""
    
    # åˆå§‹åŒ–Claudeï¼ˆä¸“é—¨ç”¨äºå¤æ‚æŠ€æœ¯åˆ†æï¼‰
    claude_provider = ClaudeProvider()
    claude_provider.initialize(
        api_key=config.get('claude', {}).get('api_key', ''),
        default_model=config.get('claude', {}).get('default_model', 'claude-3-sonnet-20240229')
    )
    llm_manager.register_provider('claude', claude_provider)
    
    # åˆå§‹åŒ–Geminiï¼ˆä¸“é—¨ç”¨äºä»£ç ç”Ÿæˆå’ŒæŠ€æœ¯å®ç°ï¼‰
    gemini_provider = GeminiProvider()
    gemini_provider.initialize(
        api_key=config.get('gemini', {}).get('api_key', ''),
        default_model=config.get('gemini', {}).get('default_model', 'gemini-1.5-flash')
    )
    llm_manager.register_provider('gemini', gemini_provider)
    
    # åˆå§‹åŒ–Volces Deepseekï¼ˆä¸“é—¨ç”¨äºæ·±åº¦æ¨ç†å’Œåˆ†æï¼‰
    if 'volcesDeepseek' in config:
        volces_provider = VolcesDeepseekProvider()
        volces_provider.initialize(
            api_key=config.get('volcesDeepseek', {}).get('api_key', ''),
            url=config.get('volcesDeepseek', {}).get('url', 'https://ark.cn-beijing.volces.com/api/v3/chat/completions'),
            model=config.get('volcesDeepseek', {}).get('model', 'deepseek-r1-250528'),
            max_tokens=config.get('volcesDeepseek', {}).get('max_tokens', 16191)
        )
        llm_manager.register_provider('volcesDeepseek', volces_provider)
    
    # åˆå§‹åŒ–Qwen Plusï¼ˆä¸“é—¨ç”¨äºä¸­æ–‡ç†è§£å’Œå¤šæ¨¡æ€å¤„ç†ï¼‰
    if 'qwen-plus' in config:
        qwen_provider = QwenPlusProvider()
        qwen_provider.initialize(
            api_key=config.get('qwen-plus', {}).get('api_key', ''),
            url=config.get('qwen-plus', {}).get('url', 'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions'),
            model=config.get('qwen-plus', {}).get('model', 'qwen-plus-2025-04-28'),
            max_tokens=config.get('qwen-plus', {}).get('max_tokens', 16191)
        )
        llm_manager.register_provider('qwen-plus', qwen_provider)
    
    # è®¾ç½®é»˜è®¤æä¾›å•†
    default_provider = config.get('default_provider', 'claude')
    if default_provider in llm_manager.get_all_providers():
        llm_manager.set_default_provider(default_provider)
    
    # åˆå§‹åŒ–æ¨¡å‹é€‰æ‹©å™¨
    llm_manager.initialize_model_selector()
    
    logger.info(f"Initialized LLM providers for Ruishi Control Platform: {llm_manager.get_all_providers()}")
